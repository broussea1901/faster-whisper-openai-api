services:
  whisper-v2-cpu:
    build:
      context: .
      dockerfile: Dockerfile.cpu
    image: faster-whisper-v2:cpu
    container_name: whisper-v2-cpu
    ports:
      - "8000:8000"
    environment:
      # API Keys
      - API_KEYS=${API_KEYS:-}
      # Model configuration
      - MODEL_SIZE=large-v3
      - DEVICE=cpu
      - COMPUTE_TYPE=int8
      # CPU optimization
      - OMP_NUM_THREADS=${OMP_NUM_THREADS:-8}
      - MKL_NUM_THREADS=${MKL_NUM_THREADS:-8}
      # Performance tuning
      - PATIENCE=1.0
    volumes:
      # Model cache
      - whisper-models:/home/whisper/.cache
    deploy:
      resources:
        limits:
          cpus: "8"
          memory: 16G
        reservations:
          cpus: "4"
          memory: 8G
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 180s

volumes:
  whisper-models:
    driver: local
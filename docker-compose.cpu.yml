version: '3.8'

services:
  faster-whisper:
    build: 
      context: .
      dockerfile: Dockerfile.cpu
    image: faster-whisper-server:cpu
    container_name: faster-whisper-api
    ports:
      - "8000:8000"
    environment:
      # Model size: tiny, base, small, medium, large-v3
      - MODEL_SIZE=base
      # Device: cpu only for this configuration
      - DEVICE=cpu
      # Compute type: float32 or int8 for CPU
      - COMPUTE_TYPE=int8
      # API Keys (comma-separated), leave empty for no auth
      - API_KEYS=your-secret-key-1,your-secret-key-2
    volumes:
      # Optional: Mount model cache to avoid re-downloading
      - whisper-models:/home/whisper/.cache/huggingface
    restart: unless-stopped

volumes:
  whisper-models:

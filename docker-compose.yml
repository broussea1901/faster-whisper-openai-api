version: '3.8'

services:
  faster-whisper:
    build: .
    image: faster-whisper-server:latest
    container_name: faster-whisper-api
    ports:
      - "8000:8000"
    environment:
      # Model size: tiny, base, small, medium, large-v3
      - MODEL_SIZE=base
      # Device: cuda (GPU), cpu, or auto
      - DEVICE=cuda
      # Compute type: float16, int8_float16, int8 (for CPU: float32, int8)
      - COMPUTE_TYPE=float16
      # API Keys (comma-separated), leave empty for no auth
      - API_KEYS=your-secret-key-1,your-secret-key-2
    volumes:
      # Optional: Mount model cache to avoid re-downloading
      - whisper-models:/home/whisper/.cache/huggingface
    restart: unless-stopped
    # GPU support configuration
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

volumes:
  whisper-models:
